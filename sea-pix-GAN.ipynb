{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device cpu\n"
     ]
    }
   ],
   "source": [
    "import torch as th\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import pandas as pd\n",
    "\n",
    "device = th.device(\"cuda\" if th.cuda.is_available() else \"cpu\")\n",
    "device = th.device(\"cpu\")\n",
    "print(f\"Using device {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = {\n",
    "    \"learning_rate\": 2e-4,\n",
    "    \"batch_size\": 64,\n",
    "    \"epochs\": 150,\n",
    "    \"l1_lambda\": 100,\n",
    "    \"adam_betas\": (0.5, 0.999), # default values are (0.9, 0.999)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "## Discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DownModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, leaky_relu_slope=0.2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.lrelu = nn.LeakyReLU(leaky_relu_slope)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lrelu(x)\n",
    "        return x      \n",
    "    \n",
    "class ZeroPadModule(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = F.pad(x, (1, 1, 1, 1), mode='constant', value=0)\n",
    "        return x\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    \n",
    "    def __init__(self, DEBUG=False):\n",
    "        super().__init__()\n",
    "        self.DEBUG = DEBUG\n",
    "        \n",
    "        self.DownLayers = nn.Sequential(\n",
    "            DownModule(6, 64),\n",
    "            DownModule(64, 128),\n",
    "            DownModule(128, 256),\n",
    "            ZeroPadModule(),\n",
    "            nn.Conv2d(256, 512, kernel_size=4, stride=1, padding=0),\n",
    "            nn.BatchNorm2d(512),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            ZeroPadModule(),\n",
    "            nn.Conv2d(512, 1, kernel_size=4, stride=1, padding=0),\n",
    "            nn.Sigmoid() #NOTE: Not actually in the paper, but required for the BCELoss (limits values to [0,1])\n",
    "        )\n",
    "        \n",
    "    def forward(self, x: th.Tensor, y: th.Tensor) -> th.Tensor:\n",
    "        \"\"\"Forward pass of the discriminator\n",
    "\n",
    "        Args:\n",
    "            x (th.Tensor): Raw underwater image\n",
    "            y (th.Tensor): Enhanced underwater image\n",
    "\n",
    "        Returns:\n",
    "            th.Tensor: Output tensor measuring the realness of the input images\n",
    "        \"\"\"\n",
    "        \n",
    "        z = th.concatenate((x, y), dim=1)\n",
    "        \n",
    "        # Input tensor shape\n",
    "        if self.DEBUG:\n",
    "            print(\"Input tensor shape:\")\n",
    "            print(z.shape)\n",
    "        \n",
    "        # TODO: Convolutions\n",
    "        \n",
    "        for layer in self.DownLayers:\n",
    "            z = layer(z)\n",
    "            if self.DEBUG:\n",
    "                print(z.shape)\n",
    "        \n",
    "        return z\n",
    "    \n",
    "#discriminator = Discriminator(DEBUG=True).to(device)\n",
    "\n",
    "#ample = th.randn(1, 3, 256, 256, device=device)\n",
    "#clone = sample.clone()\n",
    "#output = discriminator(sample, clone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generator / Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, leaky_relu_slope=0.2):\n",
    "        super().__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.lrelu = nn.LeakyReLU(leaky_relu_slope)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.lrelu(x)\n",
    "        return x      \n",
    "\n",
    "class FeatureMapModule(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels, leaky_relu_slope=0.2):\n",
    "            super().__init__()\n",
    "            self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "            self.lrelu = nn.LeakyReLU(leaky_relu_slope)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.conv(x)\n",
    "            x = self.lrelu(x)\n",
    "            return x      \n",
    "\n",
    "class DecoderModule(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, dropout_prob=0.5):\n",
    "        super().__init__()\n",
    "        self.deconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.dropout = nn.Dropout(dropout_prob)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.deconv(x)\n",
    "        x = self.bn(x)\n",
    "        x = self.dropout(x)\n",
    "        x = self.relu(x)\n",
    "        return x\n",
    "    \n",
    "class OutputModule(nn.Module):\n",
    "        def __init__(self, in_channels, out_channels):\n",
    "            super().__init__()\n",
    "            self.deconv = nn.ConvTranspose2d(in_channels, out_channels, kernel_size=4, stride=2, padding=1)\n",
    "            \n",
    "        def forward(self, x):\n",
    "            x = self.deconv(x)\n",
    "            return x\n",
    "\n",
    "class Autoencoder(nn.Module):\n",
    "    \"\"\"\n",
    "    Autoencoder model for image generation\n",
    "\n",
    "    A residual autoencoder model for image generation. \n",
    "    The final model will be an image-to-image translation model\n",
    "    that enhances underwater images.\n",
    "    \"\"\"\n",
    "    def __init__(self, DEBUG=False):\n",
    "        super().__init__()\n",
    "        self.DEBUG = DEBUG\n",
    "\n",
    "        self.EncoderLayers = nn.ModuleList([\n",
    "            EncoderModule(3, 64),\n",
    "            EncoderModule(64, 128),\n",
    "            EncoderModule(128, 256),\n",
    "            EncoderModule(256, 512),\n",
    "            EncoderModule(512, 512),\n",
    "            EncoderModule(512, 512),\n",
    "            EncoderModule(512, 512),\n",
    "            FeatureMapModule(512, 512),\n",
    "        ])\n",
    "        \n",
    "        self.DecoderLayers = nn.ModuleList([\n",
    "            DecoderModule(512, 512),\n",
    "            DecoderModule(1024, 512),\n",
    "            DecoderModule(1024, 512),\n",
    "            DecoderModule(1024, 512, dropout_prob=0.0),\n",
    "            DecoderModule(1024, 256, dropout_prob=0.0),\n",
    "            DecoderModule(512, 128, dropout_prob=0.0),\n",
    "            DecoderModule(256, 64, dropout_prob=0.0),\n",
    "        ])\n",
    "        \n",
    "        self.OutputLayer = OutputModule(128, 3)\n",
    "        \n",
    "    def forward(self, x, z):\n",
    "        \"\"\"Forward pass for the autoencoder model.\n",
    "\n",
    "        Args:\n",
    "            x (th.Tensor): Input image tensor\n",
    "            z (th.Tensor): Noise tensor\n",
    "\n",
    "        Returns:\n",
    "            th.Tensor: Output image tensor\n",
    "        \"\"\"\n",
    "\n",
    "        #TODO: Figure out precisely how the noise tensor is used. Tentaively we add them together.\n",
    "        x = x + z\n",
    "\n",
    "        # Store the activations of the encoder layers for skip connections\n",
    "        layer_outputs = []\n",
    "        \n",
    "        if self.DEBUG:\n",
    "            print(\"Starting forward pass\")\n",
    "            print(x.shape)\n",
    "        \n",
    "        # Encoder pass\n",
    "        for i in range(len(self.EncoderLayers)):\n",
    "            x = self.EncoderLayers[i](x)\n",
    "            if i < len(self.EncoderLayers) - 1:\n",
    "                layer_outputs.append(x)\n",
    "            if self.DEBUG:\n",
    "                print(x.shape)\n",
    "        \n",
    "        if self.DEBUG:\n",
    "            print(\"Encoding complete\")\n",
    "            print(x.shape)\n",
    "        \n",
    "        \n",
    "        #[print(\"Stored activations: \",x.shape) for x in layer_outputs]\n",
    "        \n",
    "        # Decoder pass      \n",
    "        for i in range(len(self.DecoderLayers)):\n",
    "            \n",
    "            if i != 0:\n",
    "                # Get the appropriate encoder activation\n",
    "                s = layer_outputs.pop()\n",
    "                \n",
    "                # If the shapes match, concatenate the activations\n",
    "                if x.shape == s.shape:\n",
    "                    x = th.cat((x, s), 1)\n",
    "                    \n",
    "                else:\n",
    "                    print(\"Error, shapes do not match\")\n",
    "                    print(\"X:\", x.shape)\n",
    "                    print(\"S:\", s.shape)\n",
    "                    return th.tensor([])\n",
    "\n",
    "            # Pass the concatenated activations through the decoder layer\n",
    "            x = self.DecoderLayers[i](x)\n",
    "            if self.DEBUG:\n",
    "                print(x.shape)\n",
    "                 \n",
    "        if self.DEBUG:\n",
    "            print(\"Decoding complete\")\n",
    "        \n",
    "        # Perform the final deconvolution\n",
    "        x = th.cat((x, layer_outputs.pop()), 1)\n",
    "        x = self.OutputLayer(x)\n",
    "        \n",
    "        if self.DEBUG:\n",
    "            print(\"Is layer_outputs empty:\", len(layer_outputs) == 0)\n",
    "            print(x.shape)\n",
    "            print(\"Output complete\")\n",
    "            \n",
    "        return x\n",
    " \n",
    "#generator = Autoencoder(DEBUG=True).to(device)\n",
    "\n",
    "#sample = th.randn(1, 3, 256, 256, device=device)\n",
    "#noise = th.randn(1, 3, 256, 256, device=device)\n",
    "#output = generator(sample, noise)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Loop\n",
    "\n",
    "## Defining the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, discriminator, generator, d_optimizer, g_optimizer, device, epochs=150, l1_lambda=100):\n",
    "    \n",
    "    loss_stats = pd.DataFrame(columns=[\"Epoch\",\"d_loss\", \"g_loss\", \"g_GAN_loss\", \"g_L1_loss\"])\n",
    "    \n",
    "    # Define the loss functions\n",
    "    d_real_loss = th.nn.BCELoss()\n",
    "    d_gan_loss = th.nn.BCELoss()\n",
    "    g_gan_loss = th.nn.BCELoss()\n",
    "    g_l1_loss = th.nn.L1Loss()\n",
    "            \n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        for batch, (x, y) in enumerate(dataloader):\n",
    "                \n",
    "            x, y = x.to(device), y.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            d_optimizer.zero_grad()\n",
    "            g_optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            z = generator(x, y)\n",
    "            d_real = discriminator(x, y)\n",
    "            d_fake = discriminator(x, z)\n",
    "            \n",
    "            # Compute the loss\n",
    "            drl = d_real_loss(d_real, th.ones_like(d_real))\n",
    "            dgl = d_gan_loss(d_fake, th.zeros_like(d_fake))\n",
    "            \n",
    "            ggl = g_gan_loss(d_fake, th.ones_like(d_fake))\n",
    "            gl1 = g_l1_loss(z, y)\n",
    "            \n",
    "            d_loss = drl + dgl\n",
    "            g_loss = ggl + l1_lambda * gl1\n",
    "            \n",
    "            # Backward pass\n",
    "            d_loss.backward(retain_graph=True)\n",
    "            g_loss.backward()\n",
    "            \n",
    "            # Update weights\n",
    "            d_optimizer.step()\n",
    "            g_optimizer.step()\n",
    "            \n",
    "            # Print statistics\n",
    "            #TODO: Print the loss statistics at the end of each epoch\n",
    "            if batch % len(dataloader) == 0:\n",
    "                print(f\"Epoch {epoch}, batch {batch}, d_loss: {d_loss.item():.2f}, g_loss: {g_loss.item():.2f}\")\n",
    "                \n",
    "            # Save the loss statistics\n",
    "            loss_stats = pd.concat(\n",
    "                [loss_stats, pd.DataFrame(\n",
    "                    {\"Epoch\": epoch,\n",
    "                     \"d_loss\": d_loss.item(), \n",
    "                     \"g_loss\": g_loss.item(), \n",
    "                     \"g_GAN_loss\": ggl.item(), \n",
    "                     \"g_L1_loss\": gl1.item()\n",
    "                     }, index=[0])\n",
    "                 ]\n",
    "                )\n",
    "\n",
    "        #display(loss_stats.head())\n",
    "        \n",
    "        \n",
    "    return loss_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random noise to test loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 2 batches of random images of dimensions (3, 256, 256)\n",
    "batch1 = np.array([np.random.rand(3, 256, 256) for _ in range(64)])\n",
    "batch2 = np.array([np.random.rand(3, 256, 256) for _ in range(64)])\n",
    "\n",
    "# Normalize the images to the range [0, 1]\n",
    "batch1 = batch1 / 255\n",
    "batch2 = batch2 / 255\n",
    "\n",
    "# Convert the images to tensors\n",
    "batch1 = th.tensor(batch1, dtype=th.float32)\n",
    "batch2 = th.tensor(batch2, dtype=th.float32)\n",
    "\n",
    "# Create a dataloader\n",
    "dataloader = th.utils.data.DataLoader(th.utils.data.TensorDataset(batch1, batch2), batch_size=hyperparams[\"batch_size\"])\n",
    "\n",
    "# Sample a batch from the dataloader\n",
    "#sample = next(iter(dataloader))\n",
    "\n",
    "# Display the shape of the sample\n",
    "#print(sample[0].shape, sample[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running the loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, batch 0, d_loss: 1.43, g_loss: 70.67\n",
      "Epoch 1, batch 0, d_loss: 1.61, g_loss: 64.59\n",
      "Epoch 2, batch 0, d_loss: 2.04, g_loss: 59.51\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epoch</th>\n",
       "      <th>d_loss</th>\n",
       "      <th>g_loss</th>\n",
       "      <th>g_GAN_loss</th>\n",
       "      <th>g_L1_loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>1.425936</td>\n",
       "      <td>70.665131</td>\n",
       "      <td>0.798230</td>\n",
       "      <td>0.698669</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1.610332</td>\n",
       "      <td>64.585403</td>\n",
       "      <td>1.229951</td>\n",
       "      <td>0.633555</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>2.035316</td>\n",
       "      <td>59.514290</td>\n",
       "      <td>1.853227</td>\n",
       "      <td>0.576611</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Epoch    d_loss     g_loss  g_GAN_loss  g_L1_loss\n",
       "0     0  1.425936  70.665131    0.798230   0.698669\n",
       "0     1  1.610332  64.585403    1.229951   0.633555\n",
       "0     2  2.035316  59.514290    1.853227   0.576611"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_set = dataloader\n",
    "\n",
    "generator = Autoencoder().to(device)\n",
    "discriminator = Discriminator().to(device)\n",
    "\n",
    "d_optimizer = optim.Adam(\n",
    "    discriminator.parameters(), \n",
    "    lr=hyperparams[\"learning_rate\"],\n",
    "    betas=hyperparams[\"adam_betas\"],\n",
    "    maximize=True,\n",
    ")\n",
    "\n",
    "g_optimizer = optim.Adam(\n",
    "    generator.parameters(), \n",
    "    lr=hyperparams[\"learning_rate\"],\n",
    "    betas=hyperparams[\"adam_betas\"],\n",
    "    maximize=False,\n",
    ")\n",
    "\n",
    "loss_stats = train_loop(train_set, discriminator, generator, d_optimizer, g_optimizer, device, epochs=3)\n",
    "\n",
    "display(loss_stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model evaluation\n",
    "\n",
    "## Defining the metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PSNR(x, y):\n",
    "    # Maximum possible pixel value\n",
    "    MAX = 1.0\n",
    "    return 10 * np.log10(MAX / np.mean((x - y) ** 2))\n",
    "\n",
    "def SSIM(x, y):\n",
    "    # Maximum possible pixel value\n",
    "    L = 1.0\n",
    "    \n",
    "    # Constants\n",
    "    C1 = (0.01 * L) ** 2\n",
    "    C2 = (0.03 * L) ** 2\n",
    "    \n",
    "    mu_x = np.mean(x)\n",
    "    mu_y = np.mean(y)\n",
    "    \n",
    "    sigma_x = np.mean((x - mu_x) ** 2)\n",
    "    sigma_y = np.mean((y - mu_y) ** 2)\n",
    "    \n",
    "    sigma_xy = np.mean((x - mu_x) * (y - mu_y))\n",
    "    \n",
    "    num = (2 * mu_x * mu_y + C1) * (2 * sigma_xy + C2)\n",
    "    den = (mu_x ** 2 + mu_y ** 2 + C1) * (sigma_x + sigma_y + C2)\n",
    "    \n",
    "    return np.mean(num / den)\n",
    "\n",
    "def UIQM(x):\n",
    "    c1 = 0.0282\n",
    "    c2 = 0.2953\n",
    "    c3 = 3.5753\n",
    "    \n",
    "    #TODO: Implement the rest of the function\n",
    "    UICM = 0\n",
    "    UISM = 0\n",
    "    UIConM = 0\n",
    "    \n",
    "    return c1 * UICM + c2 * UISM + c3 * UIConM\n",
    "\n",
    "def get_metrics(test_data, generator):\n",
    "    metrics = pd.DataFrame(columns=[\"PSNR\", \"SSIM\", \"UIQM\"])\n",
    "    \n",
    "    #TODO: Limit the number of images to 500\n",
    "    \n",
    "    for i, (x, y) in enumerate(test_data):\n",
    "        x = x.to(device)\n",
    "        y = y.detach().numpy()\n",
    "        \n",
    "        noise = th.randn(x.shape, dtype=th.float32).to(device)\n",
    "        \n",
    "        enhanced = generator(x, noise).detach().numpy()\n",
    "        \n",
    "        psnr = PSNR(y, enhanced)\n",
    "        ssim = SSIM(y, enhanced)\n",
    "        uiqm = UIQM(enhanced)\n",
    "        \n",
    "        metrics.loc[i] = [psnr, ssim, uiqm]\n",
    "        \n",
    "    return metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the test metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Mean</th>\n",
       "      <th>Std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>PSNR</th>\n",
       "      <td>-0.537512</td>\n",
       "      <td>0.012694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SSIM</th>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>UIQM</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Mean       Std\n",
       "PSNR -0.537512  0.012694\n",
       "SSIM  0.000095  0.000008\n",
       "UIQM  0.000000  0.000000"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#TODO: Replace the random noise with the actual test data\n",
    "test_data = th.utils.data.DataLoader(th.utils.data.TensorDataset(batch1, batch2), batch_size=1)\n",
    "\n",
    "raw_metrics = get_metrics(test_data, generator)\n",
    "\n",
    "summary = pd.DataFrame(columns=[\"Mean\", \"Std\"])\n",
    "\n",
    "summary.loc[\"PSNR\"] = [raw_metrics[\"PSNR\"].mean(), raw_metrics[\"PSNR\"].std()]\n",
    "summary.loc[\"SSIM\"] = [raw_metrics[\"SSIM\"].mean(), raw_metrics[\"SSIM\"].std()]\n",
    "summary.loc[\"UIQM\"] = [raw_metrics[\"UIQM\"].mean(), raw_metrics[\"UIQM\"].std()]\n",
    "\n",
    "display(summary)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
